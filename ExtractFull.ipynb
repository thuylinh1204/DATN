{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNJA8Q90Wcr9idV5czY0EmI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuylinh1204/DATN/blob/CrawlData/ExtractFull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JtDCAzyRtSJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines\n",
        "!pip install python-docx "
      ],
      "metadata": {
        "id": "Bo3DHnXzl61h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "from google.colab import files\n",
        "import jsonlines\n",
        "import json\n",
        "from copy import deepcopy"
      ],
      "metadata": {
        "id": "kv3edA0csf_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number= []\n",
        "i=0\n",
        "while i<70:\n",
        "  for j in range (0,20):\n",
        "    number.append(str(i+1)+'.'+str(j))   \n",
        "  i+=1\n",
        "\n",
        "character= ['a)','b)','c)','d)','đ)','e).','f)','g)','h)','i)','k)',\n",
        "       'l)','m)','n)','o)','p)','q)','s)','t)','u)','v)','x)','y)','z)',\n",
        "       '(i)','(ii)','(iii)','(iv)','(v)','(vi)','(vii)','(viii)','(ix)','(x)',\n",
        "       '(xi)','(xii)','(xiii)','(xiv)','(xv)','(xvi)','(xvii)','(xviii)','(xix)']"
      ],
      "metadata": {
        "id": "IHw-dVS6aAQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "part = 'Phần'\n",
        "chapter = 'Chương'\n",
        "section = 'Mục'\n",
        "episode = 'Điểm'\n",
        "episode_luat = 'Điều'\n",
        "tags= []\n",
        "tags =[*number, *character] \n"
      ],
      "metadata": {
        "id": "j371b_WnQwBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_parts = ['Chương','Mục','Điều','Điểm', *tags]\n",
        "not_chapters =  ['Phần','Mục','Điều','Điểm',*tags]\n",
        "not_sections = ['Phần','Chương','Điều','Điểm',*tags]\n",
        "not_episodes = ['Phần','Chương','Mục',*tags]      \n",
        "not_tags = ['Phần','Chương','Điều','Mục','Điểm']"
      ],
      "metadata": {
        "id": "D065KvH33BaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def formatText (start_i,doc_len, doc,episode):\n",
        "  array_part = []\n",
        "  index_part = -1\n",
        "  index_chapter = -1\n",
        "  index_section = -1\n",
        "  index_episode = -1\n",
        "  index_context = -1\n",
        "  phan = {}\n",
        "  i= start_i\n",
        "  n= doc_len\n",
        "  while i<n-1:\n",
        "    line = doc.paragraphs[i].text\n",
        "    if line.startswith(part):\n",
        "        if index_part >= 0:\n",
        "            array_part.append(deepcopy(phan))\n",
        "            index_chapter = -1\n",
        "            index_section = -1\n",
        "            index_episode = -1\n",
        "            index_context = -1\n",
        "            phan = {}\n",
        "        index_part += 1 \n",
        "\n",
        "\n",
        "        part_name = doc.paragraphs[i+1].text\n",
        "        index_part +=1  \n",
        "        i+=2\n",
        "        next_line = doc.paragraphs[i].text\n",
        "        while not next_line.startswith(tuple(not_parts)): \n",
        "          part_name += '  '+next_line\n",
        "          i+=1\n",
        "          next_line = doc.paragraphs[i].text\n",
        "        phan['part_name'] = part_name\n",
        "        phan['chapter'] = []\n",
        "        continue\n",
        "    \n",
        "    elif line.startswith(chapter):\n",
        "        if index_chapter >= 0:\n",
        "            index_section = -1\n",
        "            index_episode = -1\n",
        "            index_context = -1\n",
        "        index_chapter += 1\n",
        "\n",
        "        chapter_name = doc.paragraphs[i+1].text\n",
        "        i+=2\n",
        "        next_line = doc.paragraphs[i].text\n",
        "        while not next_line.startswith(tuple(not_chapters)): \n",
        "          chapter_name += '  '+next_line\n",
        "          i+=1\n",
        "          next_line = doc.paragraphs[i].text\n",
        "        phan['chapter'].append({})\n",
        "        phan['chapter'][index_chapter]['chapter_name'] = chapter_name\n",
        "        phan['chapter'][index_chapter]['section'] = []\n",
        "        continue\n",
        "\n",
        "    elif line.startswith(section):\n",
        "        if index_section >= 0:\n",
        "            index_episode = -1\n",
        "            index_context = -1\n",
        "        index_section += 1\n",
        "\n",
        "        section_name = doc.paragraphs[i+1].text\n",
        "        i+=2\n",
        "        next_line = doc.paragraphs[i].text\n",
        "        while not next_line.startswith(tuple(not_sections)): \n",
        "          section_name += '  '+next_line\n",
        "          i+=1\n",
        "          next_line = doc.paragraphs[i].text\n",
        "\n",
        "        phan['chapter'][index_chapter]['section'].append({})\n",
        "        phan['chapter'][index_chapter]['section'][index_section]['section_name'] = section_name\n",
        "        phan['chapter'][index_chapter]['section'][index_section]['episode'] = []\n",
        "        continue\n",
        "\n",
        "    elif line.startswith(episode):\n",
        "          if index_episode >= 0:\n",
        "              index_context = -1\n",
        "          index_episode += 1\n",
        "          episode_name = doc.paragraphs[i].text\n",
        "          if index_chapter == -1:\n",
        "              index_chapter += 1 \n",
        "              phan['chapter'].append({})\n",
        "              phan['chapter'][index_chapter]['section'] = []\n",
        "              index_section+=1\n",
        "              phan['chapter'][index_chapter]['section'].append({})\n",
        "              phan['chapter'][index_chapter]['section'][index_section]['episode'] = []\n",
        "          if index_section == -1:\n",
        "              index_section+=1\n",
        "              phan['chapter'][index_chapter]['section'].append({})\n",
        "              phan['chapter'][index_chapter]['section'][index_section]['episode'] = []    \n",
        "          i+=1\n",
        "          \n",
        "          phan['chapter'][index_chapter]['section'][index_section]['episode'].append({})\n",
        "          phan['chapter'][index_chapter]['section'][index_section]['episode'][index_episode]['episode_name'] = episode_name\n",
        "          phan['chapter'][index_chapter]['section'][index_section]['episode'][index_episode]['context'] = []\n",
        "          continue\n",
        "\n",
        "    elif (line.startswith(tag) for tag in tags):\n",
        "        context= doc.paragraphs[i].text\n",
        "        index_context+=1\n",
        "        phan['chapter'][index_chapter]['section'][index_section]['episode'][index_episode]['context'].append(doc.paragraphs[i].text)\n",
        "        i+=1\n",
        "  return array_part       \n"
      ],
      "metadata": {
        "id": "rgo48Ur4Mv4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/drive/MyDrive/PhapLuat/Thong_Tu_01_HN.docx' \n",
        "doc = docx.Document(file_name)"
      ],
      "metadata": {
        "id": "31WCFv7Wmh_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(doc.paragraphs)\n",
        "n"
      ],
      "metadata": {
        "id": "GZbnVBpoL9Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phan = formatText (12,n,doc,episode)"
      ],
      "metadata": {
        "id": "I4Qdg0d0yycq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = []\n",
        "for i in range(4, 9):\n",
        "  time.append(doc.paragraphs[i].text)\n",
        "time[0:5] = [' '.join(time[0:5])]\n",
        "title = []\n",
        "for i in range(2, 4):\n",
        "  title.append(doc.paragraphs[i].text)\n",
        "\n",
        "title[0:2] = [' '.join(title[0:2])]\n",
        "base = []\n",
        "for i in range(9,12):\n",
        "  base.append(doc.paragraphs[i].text)"
      ],
      "metadata": {
        "id": "d2VgL_NYrN9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rule = list()\n",
        "processed = dict()\n",
        "processed['title'] = title\n",
        "processed['time'] = time\n",
        "processed['base'] = base\n",
        "processed['contents'] = phan\n",
        "\n",
        "rule.append(processed)"
      ],
      "metadata": {
        "id": "1VJ_XvweypT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(rule)"
      ],
      "metadata": {
        "id": "a7njylxSwJqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name_luat = '/content/drive/MyDrive/PhapLuat/2022-11-Luat_So_huu_tri_tue-HN_lan_3.docx' \n",
        "doc_luat = docx.Document(file_name_luat)"
      ],
      "metadata": {
        "id": "8bM52GBVwgmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_luat =len(doc.paragraphs)\n",
        "n_luat"
      ],
      "metadata": {
        "id": "XhUcjWd9wqR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_part= formatText (14,n_luat,doc_luat,episode_luat)"
      ],
      "metadata": {
        "id": "Smcozt7p0Kyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_luat = []\n",
        "for i in range(6, 10):\n",
        "  time_luat.append(doc_luat.paragraphs[i].text)\n",
        "\n",
        "time_luat[0:5] = [' '.join(time_luat[0:5])]\n",
        "title_luat = []\n",
        "for i in range(3, 5):\n",
        "  title_luat.append(doc_luat.paragraphs[i].text)\n",
        "title_luat[0:2] = [' '.join(title_luat[0:2])]\n",
        "print(title_luat)\n",
        "base_luat = []\n",
        "for i in range(11, 12):\n",
        "  base_luat.append(doc_luat.paragraphs[i].text)"
      ],
      "metadata": {
        "id": "zgOaN8BlxT1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rule_luat = list()\n",
        "processed_luat = dict()\n",
        "processed_luat['title'] = title_luat\n",
        "processed_luat['time'] = time_luat\n",
        "processed_luat['base'] = base_luat\n",
        "processed_luat['contents'] = array_part\n",
        "\n",
        "rule_luat.append(processed_luat)"
      ],
      "metadata": {
        "id": "crko6g2xwMjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rule_luat['contents']"
      ],
      "metadata": {
        "id": "AYIqcRGS3I04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join_rule = [*rule, *rule_luat]"
      ],
      "metadata": {
        "id": "ocGOhtAx0pBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(join_rule)"
      ],
      "metadata": {
        "id": "cToZUGEF3UR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with jsonlines.open('/content/drive/MyDrive/PhapLuat/join_rule.jsonl', 'w') as writer:\n",
        "    writer.write_all(join_rule)"
      ],
      "metadata": {
        "id": "kURMM0zRqFob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('/content/drive/MyDrive/PhapLuat/join_rule.jsonl', 'w', encoding='utf8') as f:\n",
        "    for entry in join_rule:\n",
        "        # print(entry, file=f)\n",
        "        json.dump(entry, f, ensure_ascii=False)\n",
        "        print('\\n', file=f)"
      ],
      "metadata": {
        "id": "G8xoprWdqz6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}